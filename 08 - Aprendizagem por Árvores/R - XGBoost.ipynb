{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e11d4dd-faa5-4e18-87a2-32cf4df51cb9",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "\n",
    "- **O XGBoost só funciona com vetores numéricos**. Sim! você precisa trabalhar em tipos de dados aqui. \n",
    "- Fonte [How to use XGBoost algorithm in R in easy steps](https://www.analyticsvidhya.com/blog/2016/01/xgboost-algorithm-easy-steps/)\n",
    "- Fonte [https://rpubs.com/dalekube/XGBoost-Iris-Classification-Example-in-R](https://rpubs.com/dalekube/XGBoost-Iris-Classification-Example-in-R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82817b9b-196d-4f95-b507-f6f68ebd10eb",
   "metadata": {},
   "source": [
    "## Carregando Biblioteca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79191084-f8a6-48f2-9efa-cca2bf714ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'xgboost' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\Adria\\AppData\\Local\\Temp\\Rtmp48Yn9C\\downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'xgboost' was built under R version 3.6.3\"\n",
      "Attaching package: 'CatEncoders'\n",
      "\n",
      "The following object is masked from 'package:base':\n",
      "\n",
      "    transform\n",
      "\n",
      "\n",
      "Attaching package: 'gplots'\n",
      "\n",
      "The following object is masked from 'package:stats':\n",
      "\n",
      "    lowess\n",
      "\n",
      "Loading required package: lattice\n",
      "Loading required package: ggplot2\n",
      "Registered S3 methods overwritten by 'ggplot2':\n",
      "  method         from \n",
      "  [.quosures     rlang\n",
      "  c.quosures     rlang\n",
      "  print.quosures rlang\n"
     ]
    }
   ],
   "source": [
    "library(repr)\n",
    "library(caTools)\n",
    "options(repr.plot.width = 8, repr.plot.height = 8)\n",
    "#Boost\n",
    "install.packages('xgboost')\n",
    "library(xgboost)\n",
    "#Preprocessamento\n",
    "library(CatEncoders)\n",
    "library(gplots)\n",
    "#Matricas\n",
    "library(caret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a14f725-2ff0-433f-8b9b-b6e360d657f3",
   "metadata": {},
   "source": [
    "## Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73f280a4-c492-4e5b-826a-ff821b8102dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>PassengerId</th><th scope=col>Survived</th><th scope=col>Pclass</th><th scope=col>Name</th><th scope=col>Sex</th><th scope=col>Age</th><th scope=col>SibSp</th><th scope=col>Parch</th><th scope=col>Ticket</th><th scope=col>Fare</th><th scope=col>Cabin</th><th scope=col>Embarked</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1                                                  </td><td>0                                                  </td><td>3                                                  </td><td>Braund, Mr. Owen Harris                            </td><td>male                                               </td><td>22                                                 </td><td>1                                                  </td><td>0                                                  </td><td>A/5 21171                                          </td><td> 7.2500                                            </td><td>NA                                                 </td><td>S                                                  </td></tr>\n",
       "\t<tr><td>2                                                  </td><td>1                                                  </td><td>1                                                  </td><td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td><td>female                                             </td><td>38                                                 </td><td>1                                                  </td><td>0                                                  </td><td>PC 17599                                           </td><td>71.2833                                            </td><td>C85                                                </td><td>C                                                  </td></tr>\n",
       "\t<tr><td>3                                                  </td><td>1                                                  </td><td>3                                                  </td><td>Heikkinen, Miss. Laina                             </td><td>female                                             </td><td>26                                                 </td><td>0                                                  </td><td>0                                                  </td><td>STON/O2. 3101282                                   </td><td> 7.9250                                            </td><td>NA                                                 </td><td>S                                                  </td></tr>\n",
       "\t<tr><td>4                                                  </td><td>1                                                  </td><td>1                                                  </td><td>Futrelle, Mrs. Jacques Heath (Lily May Peel)       </td><td>female                                             </td><td>35                                                 </td><td>1                                                  </td><td>0                                                  </td><td>113803                                             </td><td>53.1000                                            </td><td>C123                                               </td><td>S                                                  </td></tr>\n",
       "\t<tr><td>5                                                  </td><td>0                                                  </td><td>3                                                  </td><td>Allen, Mr. William Henry                           </td><td>male                                               </td><td>35                                                 </td><td>0                                                  </td><td>0                                                  </td><td>373450                                             </td><td> 8.0500                                            </td><td>NA                                                 </td><td>S                                                  </td></tr>\n",
       "\t<tr><td>6                                                  </td><td>0                                                  </td><td>3                                                  </td><td>Moran, Mr. James                                   </td><td>male                                               </td><td>NA                                                 </td><td>0                                                  </td><td>0                                                  </td><td>330877                                             </td><td> 8.4583                                            </td><td>NA                                                 </td><td>Q                                                  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllllll}\n",
       " PassengerId & Survived & Pclass & Name & Sex & Age & SibSp & Parch & Ticket & Fare & Cabin & Embarked\\\\\n",
       "\\hline\n",
       "\t 1                                                   & 0                                                   & 3                                                   & Braund, Mr. Owen Harris                             & male                                                & 22                                                  & 1                                                   & 0                                                   & A/5 21171                                           &  7.2500                                             & NA                                                  & S                                                  \\\\\n",
       "\t 2                                                   & 1                                                   & 1                                                   & Cumings, Mrs. John Bradley (Florence Briggs Thayer) & female                                              & 38                                                  & 1                                                   & 0                                                   & PC 17599                                            & 71.2833                                             & C85                                                 & C                                                  \\\\\n",
       "\t 3                                                   & 1                                                   & 3                                                   & Heikkinen, Miss. Laina                              & female                                              & 26                                                  & 0                                                   & 0                                                   & STON/O2. 3101282                                    &  7.9250                                             & NA                                                  & S                                                  \\\\\n",
       "\t 4                                                   & 1                                                   & 1                                                   & Futrelle, Mrs. Jacques Heath (Lily May Peel)        & female                                              & 35                                                  & 1                                                   & 0                                                   & 113803                                              & 53.1000                                             & C123                                                & S                                                  \\\\\n",
       "\t 5                                                   & 0                                                   & 3                                                   & Allen, Mr. William Henry                            & male                                                & 35                                                  & 0                                                   & 0                                                   & 373450                                              &  8.0500                                             & NA                                                  & S                                                  \\\\\n",
       "\t 6                                                   & 0                                                   & 3                                                   & Moran, Mr. James                                    & male                                                & NA                                                  & 0                                                   & 0                                                   & 330877                                              &  8.4583                                             & NA                                                  & Q                                                  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| PassengerId | Survived | Pclass | Name | Sex | Age | SibSp | Parch | Ticket | Fare | Cabin | Embarked |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1                                                   | 0                                                   | 3                                                   | Braund, Mr. Owen Harris                             | male                                                | 22                                                  | 1                                                   | 0                                                   | A/5 21171                                           |  7.2500                                             | NA                                                  | S                                                   |\n",
       "| 2                                                   | 1                                                   | 1                                                   | Cumings, Mrs. John Bradley (Florence Briggs Thayer) | female                                              | 38                                                  | 1                                                   | 0                                                   | PC 17599                                            | 71.2833                                             | C85                                                 | C                                                   |\n",
       "| 3                                                   | 1                                                   | 3                                                   | Heikkinen, Miss. Laina                              | female                                              | 26                                                  | 0                                                   | 0                                                   | STON/O2. 3101282                                    |  7.9250                                             | NA                                                  | S                                                   |\n",
       "| 4                                                   | 1                                                   | 1                                                   | Futrelle, Mrs. Jacques Heath (Lily May Peel)        | female                                              | 35                                                  | 1                                                   | 0                                                   | 113803                                              | 53.1000                                             | C123                                                | S                                                   |\n",
       "| 5                                                   | 0                                                   | 3                                                   | Allen, Mr. William Henry                            | male                                                | 35                                                  | 0                                                   | 0                                                   | 373450                                              |  8.0500                                             | NA                                                  | S                                                   |\n",
       "| 6                                                   | 0                                                   | 3                                                   | Moran, Mr. James                                    | male                                                | NA                                                  | 0                                                   | 0                                                   | 330877                                              |  8.4583                                             | NA                                                  | Q                                                   |\n",
       "\n"
      ],
      "text/plain": [
       "  PassengerId Survived Pclass\n",
       "1 1           0        3     \n",
       "2 2           1        1     \n",
       "3 3           1        3     \n",
       "4 4           1        1     \n",
       "5 5           0        3     \n",
       "6 6           0        3     \n",
       "  Name                                                Sex    Age SibSp Parch\n",
       "1 Braund, Mr. Owen Harris                             male   22  1     0    \n",
       "2 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female 38  1     0    \n",
       "3 Heikkinen, Miss. Laina                              female 26  0     0    \n",
       "4 Futrelle, Mrs. Jacques Heath (Lily May Peel)        female 35  1     0    \n",
       "5 Allen, Mr. William Henry                            male   35  0     0    \n",
       "6 Moran, Mr. James                                    male   NA  0     0    \n",
       "  Ticket           Fare    Cabin Embarked\n",
       "1 A/5 21171         7.2500 NA    S       \n",
       "2 PC 17599         71.2833 C85   C       \n",
       "3 STON/O2. 3101282  7.9250 NA    S       \n",
       "4 113803           53.1000 C123  S       \n",
       "5 373450            8.0500 NA    S       \n",
       "6 330877            8.4583 NA    Q       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df <- read.csv(\"../datasets/titanic/train.csv\", na.strings = '')\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd94f2b5-8b5f-4f16-9c36-91b979af4000",
   "metadata": {},
   "source": [
    "## Pré-Processamento de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19fc876d-4408-42ac-b599-0ea7ef504018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Survived</th><th scope=col>Pclass</th><th scope=col>Name</th><th scope=col>Sex</th><th scope=col>Age</th><th scope=col>SibSp</th><th scope=col>Parch</th><th scope=col>Fare</th><th scope=col>Embarked</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0         </td><td>3         </td><td>4         </td><td>2         </td><td>-0.5921480</td><td>1         </td><td>0         </td><td>-0.5021631</td><td>3         </td></tr>\n",
       "\t<tr><td>1         </td><td>1         </td><td>5         </td><td>1         </td><td> 0.6384304</td><td>1         </td><td>0         </td><td> 0.7864036</td><td>1         </td></tr>\n",
       "\t<tr><td>1         </td><td>3         </td><td>3         </td><td>1         </td><td>-0.2845034</td><td>0         </td><td>0         </td><td>-0.4885799</td><td>3         </td></tr>\n",
       "\t<tr><td>1         </td><td>1         </td><td>5         </td><td>1         </td><td> 0.4076970</td><td>1         </td><td>0         </td><td> 0.4204941</td><td>3         </td></tr>\n",
       "\t<tr><td>0         </td><td>3         </td><td>4         </td><td>2         </td><td> 0.4076970</td><td>0         </td><td>0         </td><td>-0.4860644</td><td>3         </td></tr>\n",
       "\t<tr><td>0         </td><td>3         </td><td>4         </td><td>2         </td><td> 0.0000000</td><td>0         </td><td>0         </td><td>-0.4778481</td><td>2         </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllll}\n",
       " Survived & Pclass & Name & Sex & Age & SibSp & Parch & Fare & Embarked\\\\\n",
       "\\hline\n",
       "\t 0          & 3          & 4          & 2          & -0.5921480 & 1          & 0          & -0.5021631 & 3         \\\\\n",
       "\t 1          & 1          & 5          & 1          &  0.6384304 & 1          & 0          &  0.7864036 & 1         \\\\\n",
       "\t 1          & 3          & 3          & 1          & -0.2845034 & 0          & 0          & -0.4885799 & 3         \\\\\n",
       "\t 1          & 1          & 5          & 1          &  0.4076970 & 1          & 0          &  0.4204941 & 3         \\\\\n",
       "\t 0          & 3          & 4          & 2          &  0.4076970 & 0          & 0          & -0.4860644 & 3         \\\\\n",
       "\t 0          & 3          & 4          & 2          &  0.0000000 & 0          & 0          & -0.4778481 & 2         \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Survived | Pclass | Name | Sex | Age | SibSp | Parch | Fare | Embarked |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| 0          | 3          | 4          | 2          | -0.5921480 | 1          | 0          | -0.5021631 | 3          |\n",
       "| 1          | 1          | 5          | 1          |  0.6384304 | 1          | 0          |  0.7864036 | 1          |\n",
       "| 1          | 3          | 3          | 1          | -0.2845034 | 0          | 0          | -0.4885799 | 3          |\n",
       "| 1          | 1          | 5          | 1          |  0.4076970 | 1          | 0          |  0.4204941 | 3          |\n",
       "| 0          | 3          | 4          | 2          |  0.4076970 | 0          | 0          | -0.4860644 | 3          |\n",
       "| 0          | 3          | 4          | 2          |  0.0000000 | 0          | 0          | -0.4778481 | 2          |\n",
       "\n"
      ],
      "text/plain": [
       "  Survived Pclass Name Sex Age        SibSp Parch Fare       Embarked\n",
       "1 0        3      4    2   -0.5921480 1     0     -0.5021631 3       \n",
       "2 1        1      5    1    0.6384304 1     0      0.7864036 1       \n",
       "3 1        3      3    1   -0.2845034 0     0     -0.4885799 3       \n",
       "4 1        1      5    1    0.4076970 1     0      0.4204941 3       \n",
       "5 0        3      4    2    0.4076970 0     0     -0.4860644 3       \n",
       "6 0        3      4    2    0.0000000 0     0     -0.4778481 2       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t891 obs. of  9 variables:\n",
      " $ Survived: int  0 1 1 1 0 0 0 0 1 1 ...\n",
      " $ Pclass  : Factor w/ 3 levels \"1\",\"2\",\"3\": 3 1 3 1 3 3 1 3 3 2 ...\n",
      " $ Name    : Factor w/ 7 levels \"1\",\"2\",\"3\",\"4\",..: 4 5 3 5 4 4 4 2 5 5 ...\n",
      " $ Sex     : Factor w/ 2 levels \"1\",\"2\": 2 1 1 1 2 2 2 2 1 1 ...\n",
      " $ Age     : num  -0.592 0.638 -0.285 0.408 0.408 ...\n",
      " $ SibSp   : int  1 1 0 1 0 0 0 3 0 1 ...\n",
      " $ Parch   : int  0 0 0 0 0 0 0 1 2 0 ...\n",
      " $ Fare    : num  -0.502 0.786 -0.489 0.42 -0.486 ...\n",
      " $ Embarked: Factor w/ 3 levels \"1\",\"2\",\"3\": 3 1 3 3 3 2 3 3 3 1 ...\n"
     ]
    }
   ],
   "source": [
    "# Extração de Pronomes\n",
    "df$Name <- ifelse(grepl(\", Mr. \", df$Name), 'Mr', as.character(df$Name))\n",
    "df$Name <- ifelse(grepl(\"Capt\", df$Name), 'Tripulacao', as.character(df$Name))\n",
    "df$Name <- ifelse(grepl(\"Don\", df$Name), 'Mr', as.character(df$Name))\n",
    "df$Name <- ifelse(grepl(\"Major\", df$Name), 'Tripulacao', as.character(df$Name))\n",
    "df$Name <- ifelse(grepl(\"Col\", df$Name), 'Tripulacao', as.character(df$Name))\n",
    "df$Name <- ifelse(grepl(\"Dr\", df$Name), 'Dr', as.character(df$Name))\n",
    "df$Name <- ifelse(grepl(\"Rev\", df$Name), 'Rev', as.character(df$Name))\n",
    "df$Name <- ifelse(grepl(\"Sir\", df$Name), 'Mr', as.character(df$Name))\n",
    "df$Name <- ifelse(grepl(\"Jonkheer\", df$Name), 'Mr', as.character(df$Name))\n",
    "df$Name <- ifelse(grepl(\"Dona\", df$Name), 'Mrs', as.character(df$Name))\n",
    "df$Name <- ifelse(grepl(\"Countess\", df$Name), 'Mrs', as.character(df$Name))\n",
    "df$Name <- ifelse(grepl(\"Mme\", df$Name), 'Mrs', as.character(df$Name))\n",
    "df$Name <- ifelse(grepl(\"Lady\", df$Name), 'Mrs', as.character(df$Name))\n",
    "df$Name <- ifelse(grepl(\"Mrs\", df$Name), 'Mrs', as.character(df$Name))\n",
    "df$Name <- ifelse(grepl(\"Mlle\", df$Name), 'Miss', as.character(df$Name))\n",
    "df$Name <- ifelse(grepl(\"Ms\", df$Name), 'Miss', as.character(df$Name))\n",
    "df$Name <- ifelse(grepl(\"Miss\", df$Name), 'Miss', as.character(df$Name))\n",
    "df$Name <- ifelse(grepl(\"Master\", df$Name), 'Master', as.character(df$Name))\n",
    "\n",
    "# Categóricas para Numéricas\n",
    "le_name <- LabelEncoder.fit(unique(df$Name))\n",
    "df$Name <- transform(le_name, df$Name)\n",
    "\n",
    "# Substituir valores ausentes/nulos\n",
    "media <- mean(df$Age, na.rm = TRUE)\n",
    "df$Age <- ifelse(is.na(df$Age), media, df$Age)\n",
    "\n",
    "t <- table(df$Embarked)\n",
    "moda <- names(t[t == max(t)])\n",
    "\n",
    "df$Embarked <- ifelse(is.na(df$Embarked), as.character(moda), as.character(df$Embarked) )\n",
    "\n",
    "# Categórico Para numérico\n",
    "le_sex <- LabelEncoder.fit(unique(df$Sex))\n",
    "df$Sex <- transform(le_sex, df$Sex)\n",
    "\n",
    "le_embarked <- LabelEncoder.fit(unique(df$Embarked))\n",
    "df$Embarked <- transform(le_embarked, df$Embarked)\n",
    "\n",
    "# Remoção de colunas\n",
    "df$PassengerId <- NULL\n",
    "df$Ticket <- NULL\n",
    "df$Cabin <- NULL\n",
    "\n",
    "#Escalonamento \n",
    "df[, c('Age', 'Fare')] <- scale(df[, c('Age', 'Fare')])\n",
    "\n",
    "df$Name = factor(df$Name)\n",
    "df$Pclass = factor(df$Pclass)\n",
    "df$Sex = factor(df$Sex)\n",
    "df$Embarked = factor(df$Embarked)\n",
    "\n",
    "head(df)\n",
    "str(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f677ed7-74c8-4c85-9b37-e11a6db80be3",
   "metadata": {},
   "source": [
    "# Divisão dos dados em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a80b5b2-e8f0-489d-8036-c1168d95000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(0)\n",
    "divisao <- sample.split(df$Survived, SplitRatio = 0.75)\n",
    "\n",
    "treino <- subset(df, divisao == TRUE)\n",
    "teste <-  subset(df, divisao == FALSE)\n",
    "\n",
    "x_train <- treino[,-1]\n",
    "y_train <- treino$Survived\n",
    "\n",
    "x_test <- teste[,-1]\n",
    "y_test <- teste$Survived"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ea8f2f-9999-4157-8d58-5e3b9417120d",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "Argumentos\n",
    "\n",
    "- **silent**: O valor padrão é 0. Você precisa especificar 0 para imprimir mensagens em execução, 1 para o modo silencioso.\n",
    "     booster: o valor padrão é gbtree. Você precisa especificar o booster a ser usado: gbtree (baseado em árvore) ou g-blinear (função linear).\n",
    "- **num_pbuffer**: Isso é definido automaticamente pelo xgboost, não há necessidade de ser definido pelo usuário. Leia a documentação do xgboost para mais detalhes.\n",
    "- **num_feature**: Isso é definido automaticamente pelo xgboost, não há necessidade de ser definido pelo usuário.\n",
    "- **eta** - O valor padrão é definido como 0,3. Você precisa especificar a redução do tamanho do passo usado na atualização para evitar ajustes excessivos. Após cada etapa de aumento, podemos obter diretamente os pesos dos novos recursos. e eta realmente reduz os pesos dos recursos para tornar o processo de boosting mais conservador. O intervalo é de 0 a 1. Um valor eta baixo significa que o modelo é mais robusto para overfitting.\n",
    "- **gama** - O valor padrão é definido como 0. Você precisa especificar a redução de perda mínima necessária para fazer uma partição adicional em um nó folha da árvore. Quanto maior, mais conservador será o algoritmo. O intervalo é de 0 a ∞. Quanto maior a gama, mais conservador é o algoritmo.\n",
    "- **max_depth**: O valor padrão é definido como 6. Você precisa especificar a profundidade máxima de uma árvore. O intervalo é de 1 a ∞.\n",
    "- **min_child_weight** - O valor padrão é definido como 1. Você precisa especificar a soma mínima do peso da instância (hessian) necessária em um filho. Se a etapa de partição em árvore resultar em um nó folha com a soma do peso da instância menor que min_child_weight, o processo de construção desistirá de particionamento posterior. No modo de regressão linear, isso simplesmente corresponde ao número mínimo de instâncias necessárias para estar em cada nó. Quanto maior, mais conservador será o algoritmo. O intervalo é de 0 a ∞.\n",
    " - **max_delta_step** - O valor padrão é definido como 0. Etapa delta máxima que permitimos que a estimativa de peso de cada árvore seja. Se o valor for definido como 0, significa que não há restrição. Se for definido com um valor positivo, pode ajudar a tornar a etapa de atualização mais conservadora. Normalmente este parâmetro não é necessário, mas pode ajudar na regressão logística quando a classe está extremamente desequilibrada. Defina-o para um valor de 1-10 pode ajudar a controlar a atualização. O intervalo é de 0 a ∞.\n",
    "- **subsample** - o valor padrão é definido como 1. Você precisa especificar a proporção da subamostra da instância de treinamento. Configurá-lo como 0,5 significa que o XGBoost coletou aleatoriamente metade das instâncias de dados para cultivar árvores e isso evitará o sobreajuste. O intervalo é de 0 a 1.\n",
    "- **colsample_bytree** - O valor padrão é definido como 1. Você precisa especificar a proporção da subamostra das colunas ao construir cada árvore. O intervalo é de 0 a 1.\n",
    "- **lambda e alpha** - são os termos de regularização dos pesos. O valor padrão do lambda assumido é 1 e alfa é 0.\n",
    "- **lambda_bias** - Termo de regularização L2 em polarização e tem um valor padrão de 0. \n",
    "- **base_score**: O valor padrão é definido como 0,5. Você precisa especificar a pontuação de predição inicial de todas as instâncias, tendência global.\n",
    "- **objective**: o valor padrão é definido como reg: linear. Você precisa especificar o tipo de aluno que deseja, o que inclui regressão linear, regressão logística, regressão de Poisson etc.\n",
    "- **eval_metric**: Você precisa especificar as métricas de avaliação para dados de validação, uma métrica padrão será atribuída de acordo com o objetivo (rmse para regressão e erro para classificação, precisão média média para classificação\n",
    "- **seed**: Como sempre aqui, você especifica a semente para reproduzir o mesmo conjunto de saídas. \n",
    "- **nrounds** - Devine quantas passagens nos dados haverá nos dados, caso n = 2, a segunda irá aprimorar o modelo reduzindo ainda mais a diferença entre a verdade e a previsão. \n",
    "- **nthread** - o número de threads de CPU que vamos usar;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8865cfd-2ea9-43e0-bc43-f0d9b0c70cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-mlogloss:0.539341 \n",
      "[2]\ttrain-mlogloss:0.454312 \n",
      "[3]\ttrain-mlogloss:0.395439 \n",
      "[4]\ttrain-mlogloss:0.355627 \n",
      "[5]\ttrain-mlogloss:0.326271 \n",
      "[6]\ttrain-mlogloss:0.302407 \n",
      "[7]\ttrain-mlogloss:0.286392 \n",
      "[8]\ttrain-mlogloss:0.273107 \n",
      "[9]\ttrain-mlogloss:0.257876 \n",
      "[10]\ttrain-mlogloss:0.244294 \n"
     ]
    }
   ],
   "source": [
    "set.seed(0)\n",
    "classificador <- xgboost(data = data.matrix(x_train), label = y_train, nrounds = 10, objective = \"multi:softprob\", num_class = 2,  eval_metric=\"mlogloss\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376ed119-97c5-4efb-a2c0-36f718fba76d",
   "metadata": {},
   "source": [
    "## Exibir o Gráfico de Decisção\n",
    "\n",
    "- **plot**\n",
    "- **text**\n",
    "- **rpart.plot**\n",
    "- **summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "313ee118-0ee0-4da4-866d-bb88b97e72b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "##### xgb.Booster\n",
       "raw: 88.6 Kb \n",
       "call:\n",
       "  xgb.train(params = params, data = dtrain, nrounds = nrounds, \n",
       "    watchlist = watchlist, verbose = verbose, print_every_n = print_every_n, \n",
       "    early_stopping_rounds = early_stopping_rounds, maximize = maximize, \n",
       "    save_period = save_period, save_name = save_name, xgb_model = xgb_model, \n",
       "    callbacks = callbacks, objective = \"multi:softprob\", num_class = 2, \n",
       "    eval_metric = \"mlogloss\")\n",
       "params (as set within xgb.train):\n",
       "  objective = \"multi:softprob\", num_class = \"2\", eval_metric = \"mlogloss\", validate_parameters = \"TRUE\"\n",
       "xgb.attributes:\n",
       "  niter\n",
       "callbacks:\n",
       "  cb.print.evaluation(period = print_every_n)\n",
       "  cb.evaluation.log()\n",
       "# of features: 8 \n",
       "niter: 10\n",
       "nfeatures : 8 \n",
       "evaluation_log:\n",
       "    iter train_mlogloss\n",
       "       1       0.539341\n",
       "       2       0.454312\n",
       "---                    \n",
       "       9       0.257876\n",
       "      10       0.244294"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d8b175f-da71-4b53-bb32-2d0378c99679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               Length Class              Mode       \n",
       "handle             1  xgb.Booster.handle externalptr\n",
       "raw            90699  -none-             raw        \n",
       "niter              1  -none-             numeric    \n",
       "evaluation_log     2  data.table         list       \n",
       "call              16  -none-             call       \n",
       "params             4  -none-             list       \n",
       "callbacks          2  -none-             list       \n",
       "feature_names      8  -none-             character  \n",
       "nfeatures          1  -none-             numeric    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(classificador)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee27bb6f-232a-4584-8b1c-dc13dcff7085",
   "metadata": {},
   "source": [
    "## Prever os dados de Teste\n",
    "\n",
    "- Irá retornar uma matrix contendo a probabilidade de pertencer a cada uma das classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ea493c0-4823-441f-a06a-9188665557e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>morto</th><th scope=col>vivo</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.9490601 </td><td>0.05093995</td></tr>\n",
       "\t<tr><td>0.0280771 </td><td>0.97192287</td></tr>\n",
       "\t<tr><td>0.7311389 </td><td>0.26886106</td></tr>\n",
       "\t<tr><td>0.1371471 </td><td>0.86285287</td></tr>\n",
       "\t<tr><td>0.4452842 </td><td>0.55471575</td></tr>\n",
       "\t<tr><td>0.8958550 </td><td>0.10414502</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       " morto & vivo\\\\\n",
       "\\hline\n",
       "\t 0.9490601  & 0.05093995\\\\\n",
       "\t 0.0280771  & 0.97192287\\\\\n",
       "\t 0.7311389  & 0.26886106\\\\\n",
       "\t 0.1371471  & 0.86285287\\\\\n",
       "\t 0.4452842  & 0.55471575\\\\\n",
       "\t 0.8958550  & 0.10414502\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| morto | vivo |\n",
       "|---|---|\n",
       "| 0.9490601  | 0.05093995 |\n",
       "| 0.0280771  | 0.97192287 |\n",
       "| 0.7311389  | 0.26886106 |\n",
       "| 0.1371471  | 0.86285287 |\n",
       "| 0.4452842  | 0.55471575 |\n",
       "| 0.8958550  | 0.10414502 |\n",
       "\n"
      ],
      "text/plain": [
       "     morto     vivo      \n",
       "[1,] 0.9490601 0.05093995\n",
       "[2,] 0.0280771 0.97192287\n",
       "[3,] 0.7311389 0.26886106\n",
       "[4,] 0.1371471 0.86285287\n",
       "[5,] 0.4452842 0.55471575\n",
       "[6,] 0.8958550 0.10414502"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'acuracia'"
      ],
      "text/latex": [
       "'acuracia'"
      ],
      "text/markdown": [
       "'acuracia'"
      ],
      "text/plain": [
       "[1] \"acuracia\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "80.2690582959641"
      ],
      "text/latex": [
       "80.2690582959641"
      ],
      "text/markdown": [
       "80.2690582959641"
      ],
      "text/plain": [
       "[1] 80.26906"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "previsao = predict(classificador, newdata = data.matrix(x_test), reshape=T)\n",
    "colnames(previsao) = c('morto', 'vivo')\n",
    "head(previsao)\n",
    "\n",
    "classe = ifelse((previsao[, 1] > 0.5), 0, 1)\n",
    "previsao <- classe\n",
    "\n",
    "'acuracia'\n",
    "acuracia = 100 * sum(previsao == y_test)/length(y_test)\n",
    "acuracia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefefe96-b26f-4974-938c-1e50b2587c4a",
   "metadata": {},
   "source": [
    "# Matriz de Confusão\n",
    "\n",
    "- A função **table** realiza o agrupamento dos dados\n",
    "- A função **confusionMatriz** da biblioteca **caret** também calcula a matriz de confusão + as métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2080d991-cedc-472c-96ff-f7e4eed495d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      previsao\n",
       "y_test   0   1\n",
       "     0 119  18\n",
       "     1  26  60"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matriz_confusao = table(y_test, previsao)\n",
    "matriz_confusao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63d176ff-453d-4c39-a85f-76f0751c0c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction   0   1\n",
       "         0 119  26\n",
       "         1  18  60\n",
       "                                          \n",
       "               Accuracy : 0.8027          \n",
       "                 95% CI : (0.7443, 0.8528)\n",
       "    No Information Rate : 0.6143          \n",
       "    P-Value [Acc > NIR] : 1.132e-09       \n",
       "                                          \n",
       "                  Kappa : 0.5763          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.2913          \n",
       "                                          \n",
       "            Sensitivity : 0.8686          \n",
       "            Specificity : 0.6977          \n",
       "         Pos Pred Value : 0.8207          \n",
       "         Neg Pred Value : 0.7692          \n",
       "             Prevalence : 0.6143          \n",
       "         Detection Rate : 0.5336          \n",
       "   Detection Prevalence : 0.6502          \n",
       "      Balanced Accuracy : 0.7831          \n",
       "                                          \n",
       "       'Positive' Class : 0               \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matriz = confusionMatrix(factor(previsao), factor(y_test))\n",
    "matriz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f66006d-24bf-420d-8356-27e3122a20e7",
   "metadata": {},
   "source": [
    "## Personalizando a Matriz de Confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c229fda-591e-47ee-8b6c-a881f9918d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Plot with title \"Color Key\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_palette <- colorRampPalette(c(\"red\", \"yellow\", \"green\"))\n",
    "\n",
    "col_breaks = c(0:50, 51:100, 101:300)\n",
    "\n",
    "heatmap.2(matriz_confusao,\n",
    "    Rowv = 'NA',\n",
    "    cellnote = matriz_confusao, \n",
    "    main = \"Matriz de Confusão\",\n",
    "    notecol=\"black\",      \n",
    "    density.info=\"none\",  \n",
    "    trace=\"none\",        \n",
    "    col=my_palette,       \n",
    "    breaks=col_breaks,   \n",
    "    dendrogram= 'none',     \n",
    "    Colv=\"NA\" \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f4cc86-031a-4570-9ad6-f66b3c1050b0",
   "metadata": {},
   "source": [
    "# Métricas\n",
    "\n",
    "- **Precisão** que é a fração de instâncias recuperadas que são relevantes, \n",
    "- **Recall** - que é a fração de instâncias relevantes que são recuperadas \n",
    "- **f-score** - é 2 * precisão * recall / (precisão + recall) é "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1f4d29d-a678-4a76-90e7-39cb151143c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.820689655172414"
      ],
      "text/latex": [
       "0.820689655172414"
      ],
      "text/markdown": [
       "0.820689655172414"
      ],
      "text/plain": [
       "[1] 0.8206897"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Morto'"
      ],
      "text/latex": [
       "'Morto'"
      ],
      "text/markdown": [
       "'Morto'"
      ],
      "text/plain": [
       "[1] \"Morto\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.769230769230769"
      ],
      "text/latex": [
       "0.769230769230769"
      ],
      "text/markdown": [
       "0.769230769230769"
      ],
      "text/plain": [
       "[1] 0.7692308"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Vivo'"
      ],
      "text/latex": [
       "'Vivo'"
      ],
      "text/markdown": [
       "'Vivo'"
      ],
      "text/plain": [
       "[1] \"Vivo\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.820689655172414"
      ],
      "text/latex": [
       "0.820689655172414"
      ],
      "text/markdown": [
       "0.820689655172414"
      ],
      "text/plain": [
       "[1] 0.8206897"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision(factor(previsao), factor(y_test))\n",
    "'Morto'\n",
    "precision(factor(previsao), factor(y_test), relevant = 2)\n",
    "'Vivo'\n",
    "precision(factor(previsao), factor(y_test), relevant = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38219021-a6a6-410e-86a3-589bc6d6f574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.868613138686131"
      ],
      "text/latex": [
       "0.868613138686131"
      ],
      "text/markdown": [
       "0.868613138686131"
      ],
      "text/plain": [
       "[1] 0.8686131"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Morto'"
      ],
      "text/latex": [
       "'Morto'"
      ],
      "text/markdown": [
       "'Morto'"
      ],
      "text/plain": [
       "[1] \"Morto\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.697674418604651"
      ],
      "text/latex": [
       "0.697674418604651"
      ],
      "text/markdown": [
       "0.697674418604651"
      ],
      "text/plain": [
       "[1] 0.6976744"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Vivo'"
      ],
      "text/latex": [
       "'Vivo'"
      ],
      "text/markdown": [
       "'Vivo'"
      ],
      "text/plain": [
       "[1] \"Vivo\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.868613138686131"
      ],
      "text/latex": [
       "0.868613138686131"
      ],
      "text/markdown": [
       "0.868613138686131"
      ],
      "text/plain": [
       "[1] 0.8686131"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recall(factor(previsao), factor(y_test))\n",
    "'Morto'\n",
    "recall(factor(previsao), factor(y_test), relevant = 2)\n",
    "'Vivo'\n",
    "recall(factor(previsao), factor(y_test), relevant = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c2f0412-dcf4-4f64-9939-28c56eb6eb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.843971631205674"
      ],
      "text/latex": [
       "0.843971631205674"
      ],
      "text/markdown": [
       "0.843971631205674"
      ],
      "text/plain": [
       "[1] 0.8439716"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Morto'"
      ],
      "text/latex": [
       "'Morto'"
      ],
      "text/markdown": [
       "'Morto'"
      ],
      "text/plain": [
       "[1] \"Morto\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.731707317073171"
      ],
      "text/latex": [
       "0.731707317073171"
      ],
      "text/markdown": [
       "0.731707317073171"
      ],
      "text/plain": [
       "[1] 0.7317073"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Vivo'"
      ],
      "text/latex": [
       "'Vivo'"
      ],
      "text/markdown": [
       "'Vivo'"
      ],
      "text/plain": [
       "[1] \"Vivo\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.843971631205674"
      ],
      "text/latex": [
       "0.843971631205674"
      ],
      "text/markdown": [
       "0.843971631205674"
      ],
      "text/plain": [
       "[1] 0.8439716"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "F_meas(factor(previsao), factor(y_test))\n",
    "'Morto'\n",
    "F_meas(factor(previsao), factor(y_test), relevant = 2)\n",
    "'Vivo'\n",
    "F_meas(factor(previsao), factor(y_test), relevant = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f44309e-2633-4003-80a5-aa1e81298a48",
   "metadata": {},
   "source": [
    "# Ajustar Parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84a854a9-3141-4589-8c78-646b3b11375f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-merror:0.131737 \n",
      "[2]\ttrain-merror:0.124251 \n",
      "[3]\ttrain-merror:0.127246 \n",
      "[4]\ttrain-merror:0.119760 \n",
      "[5]\ttrain-merror:0.113772 \n",
      "[6]\ttrain-merror:0.112275 \n",
      "[7]\ttrain-merror:0.115269 \n",
      "[8]\ttrain-merror:0.115269 \n",
      "[9]\ttrain-merror:0.112275 \n",
      "[10]\ttrain-merror:0.112275 \n",
      "[11]\ttrain-merror:0.109281 \n",
      "[12]\ttrain-merror:0.104790 \n",
      "[13]\ttrain-merror:0.103293 \n",
      "[14]\ttrain-merror:0.097305 \n",
      "[15]\ttrain-merror:0.095808 \n",
      "[16]\ttrain-merror:0.089820 \n",
      "[17]\ttrain-merror:0.088323 \n",
      "[18]\ttrain-merror:0.089820 \n",
      "[19]\ttrain-merror:0.089820 \n",
      "[20]\ttrain-merror:0.092814 \n",
      "[21]\ttrain-merror:0.095808 \n",
      "[22]\ttrain-merror:0.086826 \n",
      "[23]\ttrain-merror:0.083832 \n",
      "[24]\ttrain-merror:0.086826 \n",
      "[25]\ttrain-merror:0.086826 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "'acuracia'"
      ],
      "text/latex": [
       "'acuracia'"
      ],
      "text/markdown": [
       "'acuracia'"
      ],
      "text/plain": [
       "[1] \"acuracia\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "82.9596412556054"
      ],
      "text/latex": [
       "82.9596412556054"
      ],
      "text/markdown": [
       "82.9596412556054"
      ],
      "text/plain": [
       "[1] 82.95964"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(0)\n",
    "classificador <- xgboost(data = data.matrix(x_train), \n",
    "                         eta = 0.1,\n",
    "                         max_depth = 15, \n",
    "                         nround=25, \n",
    "                         subsample = 0.5,\n",
    "                         colsample_bytree = 0.5,\n",
    "                         eval_metric = \"merror\",\n",
    "                         nthread = 3,                    \n",
    "                         label = y_train,\n",
    "                         objective = \"multi:softprob\",\n",
    "                         num_class = 2,\n",
    "                        )\n",
    "\n",
    "previsao = predict(classificador, newdata = data.matrix(x_test), reshape=T)\n",
    "classe = ifelse((previsao[, 1] > 0.5), 0, 1)\n",
    "previsao <- classe\n",
    "'acuracia'\n",
    "acuracia = 100 * sum(previsao == y_test)/length(y_test)\n",
    "acuracia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6864c9b-f08f-4e27-86bd-a49145abd80e",
   "metadata": {},
   "source": [
    "# Validação Cruzada\n",
    "\n",
    "- **method = cv** - indica que iremos usar o método crossvalidation\n",
    "- **number = 10** - define o número de fold\n",
    "- **method = xgbTree** - indica que iremos usar o algorítmo de de Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "446340f2-f989-4794-9259-9b65bed511b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>eta</th><th scope=col>max_depth</th><th scope=col>gamma</th><th scope=col>colsample_bytree</th><th scope=col>min_child_weight</th><th scope=col>subsample</th><th scope=col>nrounds</th><th scope=col>Accuracy</th><th scope=col>Kappa</th><th scope=col>AccuracySD</th><th scope=col>KappaSD</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>0.3       </td><td>1         </td><td>0         </td><td>0.6       </td><td>1         </td><td>0.50      </td><td>50        </td><td>0.8125968 </td><td>0.5991972 </td><td>0.04122726</td><td>0.08800752</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>0.3       </td><td>1         </td><td>0         </td><td>0.6       </td><td>1         </td><td>0.75      </td><td>50        </td><td>0.8137328 </td><td>0.6033150 </td><td>0.04631694</td><td>0.09784588</td></tr>\n",
       "\t<tr><th scope=row>7</th><td>0.3       </td><td>1         </td><td>0         </td><td>0.6       </td><td>1         </td><td>1.00      </td><td>50        </td><td>0.8092260 </td><td>0.5923297 </td><td>0.04695794</td><td>0.09987783</td></tr>\n",
       "\t<tr><th scope=row>10</th><td>0.3       </td><td>1         </td><td>0         </td><td>0.8       </td><td>1         </td><td>0.50      </td><td>50        </td><td>0.8137328 </td><td>0.6024889 </td><td>0.04570721</td><td>0.09643140</td></tr>\n",
       "\t<tr><th scope=row>13</th><td>0.3       </td><td>1         </td><td>0         </td><td>0.8       </td><td>1         </td><td>0.75      </td><td>50        </td><td>0.8103496 </td><td>0.5944208 </td><td>0.03783577</td><td>0.08057837</td></tr>\n",
       "\t<tr><th scope=row>16</th><td>0.3       </td><td>1         </td><td>0         </td><td>0.8       </td><td>1         </td><td>1.00      </td><td>50        </td><td>0.8137203 </td><td>0.6024167 </td><td>0.04358540</td><td>0.09209431</td></tr>\n",
       "\t<tr><th scope=row>55</th><td>0.4       </td><td>1         </td><td>0         </td><td>0.6       </td><td>1         </td><td>0.50      </td><td>50        </td><td>0.8204619 </td><td>0.6163252 </td><td>0.03759774</td><td>0.08123917</td></tr>\n",
       "\t<tr><th scope=row>58</th><td>0.4       </td><td>1         </td><td>0         </td><td>0.6       </td><td>1         </td><td>0.75      </td><td>50        </td><td>0.8170911 </td><td>0.6087990 </td><td>0.04119852</td><td>0.08801159</td></tr>\n",
       "\t<tr><th scope=row>61</th><td>0.4       </td><td>1         </td><td>0         </td><td>0.6       </td><td>1         </td><td>1.00      </td><td>50        </td><td>0.8092260 </td><td>0.5923270 </td><td>0.04019822</td><td>0.08522559</td></tr>\n",
       "\t<tr><th scope=row>64</th><td>0.4       </td><td>1         </td><td>0         </td><td>0.8       </td><td>1         </td><td>0.50      </td><td>50        </td><td>0.8069788 </td><td>0.5872609 </td><td>0.04083601</td><td>0.08554035</td></tr>\n",
       "\t<tr><th scope=row>67</th><td>0.4       </td><td>1         </td><td>0         </td><td>0.8       </td><td>1         </td><td>0.75      </td><td>50        </td><td>0.8103620 </td><td>0.5953182 </td><td>0.04095376</td><td>0.08705461</td></tr>\n",
       "\t<tr><th scope=row>70</th><td>0.4       </td><td>1         </td><td>0         </td><td>0.8       </td><td>1         </td><td>1.00      </td><td>50        </td><td>0.8114732 </td><td>0.5975242 </td><td>0.04182554</td><td>0.08883558</td></tr>\n",
       "\t<tr><th scope=row>19</th><td>0.3       </td><td>2         </td><td>0         </td><td>0.6       </td><td>1         </td><td>0.50      </td><td>50        </td><td>0.8148315 </td><td>0.5994115 </td><td>0.04706839</td><td>0.10438694</td></tr>\n",
       "\t<tr><th scope=row>22</th><td>0.3       </td><td>2         </td><td>0         </td><td>0.6       </td><td>1         </td><td>0.75      </td><td>50        </td><td>0.8215356 </td><td>0.6135598 </td><td>0.03768189</td><td>0.08381644</td></tr>\n",
       "\t<tr><th scope=row>25</th><td>0.3       </td><td>2         </td><td>0         </td><td>0.6       </td><td>1         </td><td>1.00      </td><td>50        </td><td>0.8260674 </td><td>0.6239229 </td><td>0.04060450</td><td>0.09089583</td></tr>\n",
       "\t<tr><th scope=row>28</th><td>0.3       </td><td>2         </td><td>0         </td><td>0.8       </td><td>1         </td><td>0.50      </td><td>50        </td><td>0.8215356 </td><td>0.6146185 </td><td>0.03204929</td><td>0.07075925</td></tr>\n",
       "\t<tr><th scope=row>31</th><td>0.3       </td><td>2         </td><td>0         </td><td>0.8       </td><td>1         </td><td>0.75      </td><td>50        </td><td>0.8181898 </td><td>0.6105928 </td><td>0.03459707</td><td>0.07641250</td></tr>\n",
       "\t<tr><th scope=row>34</th><td>0.3       </td><td>2         </td><td>0         </td><td>0.8       </td><td>1         </td><td>1.00      </td><td>50        </td><td>0.8148439 </td><td>0.5973066 </td><td>0.04128091</td><td>0.09160423</td></tr>\n",
       "\t<tr><th scope=row>73</th><td>0.4       </td><td>2         </td><td>0         </td><td>0.6       </td><td>1         </td><td>0.50      </td><td>50        </td><td>0.8204494 </td><td>0.6145167 </td><td>0.03416995</td><td>0.07310278</td></tr>\n",
       "\t<tr><th scope=row>76</th><td>0.4       </td><td>2         </td><td>0         </td><td>0.6       </td><td>1         </td><td>0.75      </td><td>50        </td><td>0.8260549 </td><td>0.6258709 </td><td>0.04170029</td><td>0.09089356</td></tr>\n",
       "\t<tr><th scope=row>79</th><td>0.4       </td><td>2         </td><td>0         </td><td>0.6       </td><td>1         </td><td>1.00      </td><td>50        </td><td>0.8260674 </td><td>0.6258910 </td><td>0.03381921</td><td>0.07290953</td></tr>\n",
       "\t<tr><th scope=row>82</th><td>0.4       </td><td>2         </td><td>0         </td><td>0.8       </td><td>1         </td><td>0.50      </td><td>50        </td><td>0.8237578 </td><td>0.6188301 </td><td>0.04014638</td><td>0.08945097</td></tr>\n",
       "\t<tr><th scope=row>85</th><td>0.4       </td><td>2         </td><td>0         </td><td>0.8       </td><td>1         </td><td>0.75      </td><td>50        </td><td>0.8361298 </td><td>0.6457631 </td><td>0.04147142</td><td>0.09159467</td></tr>\n",
       "\t<tr><th scope=row>88</th><td>0.4       </td><td>2         </td><td>0         </td><td>0.8       </td><td>1         </td><td>1.00      </td><td>50        </td><td>0.8148065 </td><td>0.6001120 </td><td>0.04505389</td><td>0.09946370</td></tr>\n",
       "\t<tr><th scope=row>37</th><td>0.3       </td><td>3         </td><td>0         </td><td>0.6       </td><td>1         </td><td>0.50      </td><td>50        </td><td>0.8327715 </td><td>0.6402254 </td><td>0.03609750</td><td>0.08089257</td></tr>\n",
       "\t<tr><th scope=row>40</th><td>0.3       </td><td>3         </td><td>0         </td><td>0.6       </td><td>1         </td><td>0.75      </td><td>50        </td><td>0.8338951 </td><td>0.6411144 </td><td>0.03920229</td><td>0.08557255</td></tr>\n",
       "\t<tr><th scope=row>43</th><td>0.3       </td><td>3         </td><td>0         </td><td>0.6       </td><td>1         </td><td>1.00      </td><td>50        </td><td>0.8249064 </td><td>0.6215746 </td><td>0.04214523</td><td>0.09292299</td></tr>\n",
       "\t<tr><th scope=row>46</th><td>0.3       </td><td>3         </td><td>0         </td><td>0.8       </td><td>1         </td><td>0.50      </td><td>50        </td><td>0.8293883 </td><td>0.6327620 </td><td>0.04367676</td><td>0.09647361</td></tr>\n",
       "\t<tr><th scope=row>49</th><td>0.3       </td><td>3         </td><td>0         </td><td>0.8       </td><td>1         </td><td>0.75      </td><td>50        </td><td>0.8361298 </td><td>0.6465165 </td><td>0.03974424</td><td>0.08604556</td></tr>\n",
       "\t<tr><th scope=row>52</th><td>0.3       </td><td>3         </td><td>0         </td><td>0.8       </td><td>1         </td><td>1.00      </td><td>50        </td><td>0.8349938 </td><td>0.6438811 </td><td>0.03445080</td><td>0.07454968</td></tr>\n",
       "\t<tr><th scope=row>...</th><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "\t<tr><th scope=row>57</th><td>0.4       </td><td>1         </td><td>0         </td><td>0.6       </td><td>1         </td><td>0.50      </td><td>150       </td><td>0.8170537 </td><td>0.6088633 </td><td>0.03967830</td><td>0.08646431</td></tr>\n",
       "\t<tr><th scope=row>60</th><td>0.4       </td><td>1         </td><td>0         </td><td>0.6       </td><td>1         </td><td>0.75      </td><td>150       </td><td>0.8170787 </td><td>0.6075935 </td><td>0.04517046</td><td>0.10054178</td></tr>\n",
       "\t<tr><th scope=row>63</th><td>0.4       </td><td>1         </td><td>0         </td><td>0.6       </td><td>1         </td><td>1.00      </td><td>150       </td><td>0.8148190 </td><td>0.6037236 </td><td>0.04499735</td><td>0.09737310</td></tr>\n",
       "\t<tr><th scope=row>66</th><td>0.4       </td><td>1         </td><td>0         </td><td>0.8       </td><td>1         </td><td>0.50      </td><td>150       </td><td>0.8182022 </td><td>0.6108358 </td><td>0.04118420</td><td>0.09127238</td></tr>\n",
       "\t<tr><th scope=row>69</th><td>0.4       </td><td>1         </td><td>0         </td><td>0.8       </td><td>1         </td><td>0.75      </td><td>150       </td><td>0.8159301 </td><td>0.6040307 </td><td>0.03793153</td><td>0.08558172</td></tr>\n",
       "\t<tr><th scope=row>72</th><td>0.4       </td><td>1         </td><td>0         </td><td>0.8       </td><td>1         </td><td>1.00      </td><td>150       </td><td>0.8148315 </td><td>0.6037497 </td><td>0.04067354</td><td>0.08794103</td></tr>\n",
       "\t<tr><th scope=row>21</th><td>0.3       </td><td>2         </td><td>0         </td><td>0.6       </td><td>1         </td><td>0.50      </td><td>150       </td><td>0.8249313 </td><td>0.6237818 </td><td>0.04881907</td><td>0.10482018</td></tr>\n",
       "\t<tr><th scope=row>24</th><td>0.3       </td><td>2         </td><td>0         </td><td>0.6       </td><td>1         </td><td>0.75      </td><td>150       </td><td>0.8271536 </td><td>0.6284596 </td><td>0.03009296</td><td>0.06780047</td></tr>\n",
       "\t<tr><th scope=row>27</th><td>0.3       </td><td>2         </td><td>0         </td><td>0.6       </td><td>1         </td><td>1.00      </td><td>150       </td><td>0.8237953 </td><td>0.6201812 </td><td>0.03350371</td><td>0.07277306</td></tr>\n",
       "\t<tr><th scope=row>30</th><td>0.3       </td><td>2         </td><td>0         </td><td>0.8       </td><td>1         </td><td>0.50      </td><td>150       </td><td>0.8260549 </td><td>0.6257682 </td><td>0.03221092</td><td>0.07227748</td></tr>\n",
       "\t<tr><th scope=row>33</th><td>0.3       </td><td>2         </td><td>0         </td><td>0.8       </td><td>1         </td><td>0.75      </td><td>150       </td><td>0.8271411 </td><td>0.6261702 </td><td>0.03530493</td><td>0.07950582</td></tr>\n",
       "\t<tr><th scope=row>36</th><td>0.3       </td><td>2         </td><td>0         </td><td>0.8       </td><td>1         </td><td>1.00      </td><td>150       </td><td>0.8305243 </td><td>0.6354118 </td><td>0.03837048</td><td>0.08341792</td></tr>\n",
       "\t<tr><th scope=row>75</th><td>0.4       </td><td>2         </td><td>0         </td><td>0.6       </td><td>1         </td><td>0.50      </td><td>150       </td><td>0.8159176 </td><td>0.6051595 </td><td>0.04539284</td><td>0.10143975</td></tr>\n",
       "\t<tr><th scope=row>78</th><td>0.4       </td><td>2         </td><td>0         </td><td>0.6       </td><td>1         </td><td>0.75      </td><td>150       </td><td>0.8293758 </td><td>0.6332687 </td><td>0.03597345</td><td>0.07971198</td></tr>\n",
       "\t<tr><th scope=row>81</th><td>0.4       </td><td>2         </td><td>0         </td><td>0.6       </td><td>1         </td><td>1.00      </td><td>150       </td><td>0.8316479 </td><td>0.6395457 </td><td>0.03783050</td><td>0.08011641</td></tr>\n",
       "\t<tr><th scope=row>84</th><td>0.4       </td><td>2         </td><td>0         </td><td>0.8       </td><td>1         </td><td>0.50      </td><td>150       </td><td>0.8271286 </td><td>0.6283819 </td><td>0.03158352</td><td>0.06846343</td></tr>\n",
       "\t<tr><th scope=row>87</th><td>0.4       </td><td>2         </td><td>0         </td><td>0.8       </td><td>1         </td><td>0.75      </td><td>150       </td><td>0.8293758 </td><td>0.6323545 </td><td>0.03750078</td><td>0.08326921</td></tr>\n",
       "\t<tr><th scope=row>90</th><td>0.4       </td><td>2         </td><td>0         </td><td>0.8       </td><td>1         </td><td>1.00      </td><td>150       </td><td>0.8327341 </td><td>0.6409549 </td><td>0.04232199</td><td>0.09138420</td></tr>\n",
       "\t<tr><th scope=row>39</th><td>0.3       </td><td>3         </td><td>0         </td><td>0.6       </td><td>1         </td><td>0.50      </td><td>150       </td><td>0.8226966 </td><td>0.6186960 </td><td>0.02208023</td><td>0.04955715</td></tr>\n",
       "\t<tr><th scope=row>42</th><td>0.3       </td><td>3         </td><td>0         </td><td>0.6       </td><td>1         </td><td>0.75      </td><td>150       </td><td>0.8395006 </td><td>0.6564600 </td><td>0.03517712</td><td>0.07478497</td></tr>\n",
       "\t<tr><th scope=row>45</th><td>0.3       </td><td>3         </td><td>0         </td><td>0.6       </td><td>1         </td><td>1.00      </td><td>150       </td><td>0.8282647 </td><td>0.6313181 </td><td>0.03276377</td><td>0.07133382</td></tr>\n",
       "\t<tr><th scope=row>48</th><td>0.3       </td><td>3         </td><td>0         </td><td>0.8       </td><td>1         </td><td>0.50      </td><td>150       </td><td>0.8260300 </td><td>0.6234660 </td><td>0.03566748</td><td>0.07819844</td></tr>\n",
       "\t<tr><th scope=row>51</th><td>0.3       </td><td>3         </td><td>0         </td><td>0.8       </td><td>1         </td><td>0.75      </td><td>150       </td><td>0.8294007 </td><td>0.6314180 </td><td>0.04198962</td><td>0.09076021</td></tr>\n",
       "\t<tr><th scope=row>54</th><td>0.3       </td><td>3         </td><td>0         </td><td>0.8       </td><td>1         </td><td>1.00      </td><td>150       </td><td>0.8360924 </td><td>0.6476669 </td><td>0.03769462</td><td>0.08120549</td></tr>\n",
       "\t<tr><th scope=row>93</th><td>0.4       </td><td>3         </td><td>0         </td><td>0.6       </td><td>1         </td><td>0.50      </td><td>150       </td><td>0.8147940 </td><td>0.6004952 </td><td>0.03066247</td><td>0.06833994</td></tr>\n",
       "\t<tr><th scope=row>96</th><td>0.4       </td><td>3         </td><td>0         </td><td>0.6       </td><td>1         </td><td>0.75      </td><td>150       </td><td>0.8181898 </td><td>0.6098985 </td><td>0.03500017</td><td>0.07515441</td></tr>\n",
       "\t<tr><th scope=row>99</th><td>0.4       </td><td>3         </td><td>0         </td><td>0.6       </td><td>1         </td><td>1.00      </td><td>150       </td><td>0.8282272 </td><td>0.6312741 </td><td>0.04512519</td><td>0.09727712</td></tr>\n",
       "\t<tr><th scope=row>102</th><td>0.4       </td><td>3         </td><td>0         </td><td>0.8       </td><td>1         </td><td>0.50      </td><td>150       </td><td>0.8203870 </td><td>0.6175539 </td><td>0.02774708</td><td>0.06107577</td></tr>\n",
       "\t<tr><th scope=row>105</th><td>0.4       </td><td>3         </td><td>0         </td><td>0.8       </td><td>1         </td><td>0.75      </td><td>150       </td><td>0.8294132 </td><td>0.6330256 </td><td>0.04845000</td><td>0.10439148</td></tr>\n",
       "\t<tr><th scope=row>108</th><td>0.4       </td><td>3         </td><td>0         </td><td>0.8       </td><td>1         </td><td>1.00      </td><td>150       </td><td>0.8304869 </td><td>0.6363228 </td><td>0.03740496</td><td>0.07990741</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllll}\n",
       "  & eta & max\\_depth & gamma & colsample\\_bytree & min\\_child\\_weight & subsample & nrounds & Accuracy & Kappa & AccuracySD & KappaSD\\\\\n",
       "\\hline\n",
       "\t1 & 0.3        & 1          & 0          & 0.6        & 1          & 0.50       & 50         & 0.8125968  & 0.5991972  & 0.04122726 & 0.08800752\\\\\n",
       "\t4 & 0.3        & 1          & 0          & 0.6        & 1          & 0.75       & 50         & 0.8137328  & 0.6033150  & 0.04631694 & 0.09784588\\\\\n",
       "\t7 & 0.3        & 1          & 0          & 0.6        & 1          & 1.00       & 50         & 0.8092260  & 0.5923297  & 0.04695794 & 0.09987783\\\\\n",
       "\t10 & 0.3        & 1          & 0          & 0.8        & 1          & 0.50       & 50         & 0.8137328  & 0.6024889  & 0.04570721 & 0.09643140\\\\\n",
       "\t13 & 0.3        & 1          & 0          & 0.8        & 1          & 0.75       & 50         & 0.8103496  & 0.5944208  & 0.03783577 & 0.08057837\\\\\n",
       "\t16 & 0.3        & 1          & 0          & 0.8        & 1          & 1.00       & 50         & 0.8137203  & 0.6024167  & 0.04358540 & 0.09209431\\\\\n",
       "\t55 & 0.4        & 1          & 0          & 0.6        & 1          & 0.50       & 50         & 0.8204619  & 0.6163252  & 0.03759774 & 0.08123917\\\\\n",
       "\t58 & 0.4        & 1          & 0          & 0.6        & 1          & 0.75       & 50         & 0.8170911  & 0.6087990  & 0.04119852 & 0.08801159\\\\\n",
       "\t61 & 0.4        & 1          & 0          & 0.6        & 1          & 1.00       & 50         & 0.8092260  & 0.5923270  & 0.04019822 & 0.08522559\\\\\n",
       "\t64 & 0.4        & 1          & 0          & 0.8        & 1          & 0.50       & 50         & 0.8069788  & 0.5872609  & 0.04083601 & 0.08554035\\\\\n",
       "\t67 & 0.4        & 1          & 0          & 0.8        & 1          & 0.75       & 50         & 0.8103620  & 0.5953182  & 0.04095376 & 0.08705461\\\\\n",
       "\t70 & 0.4        & 1          & 0          & 0.8        & 1          & 1.00       & 50         & 0.8114732  & 0.5975242  & 0.04182554 & 0.08883558\\\\\n",
       "\t19 & 0.3        & 2          & 0          & 0.6        & 1          & 0.50       & 50         & 0.8148315  & 0.5994115  & 0.04706839 & 0.10438694\\\\\n",
       "\t22 & 0.3        & 2          & 0          & 0.6        & 1          & 0.75       & 50         & 0.8215356  & 0.6135598  & 0.03768189 & 0.08381644\\\\\n",
       "\t25 & 0.3        & 2          & 0          & 0.6        & 1          & 1.00       & 50         & 0.8260674  & 0.6239229  & 0.04060450 & 0.09089583\\\\\n",
       "\t28 & 0.3        & 2          & 0          & 0.8        & 1          & 0.50       & 50         & 0.8215356  & 0.6146185  & 0.03204929 & 0.07075925\\\\\n",
       "\t31 & 0.3        & 2          & 0          & 0.8        & 1          & 0.75       & 50         & 0.8181898  & 0.6105928  & 0.03459707 & 0.07641250\\\\\n",
       "\t34 & 0.3        & 2          & 0          & 0.8        & 1          & 1.00       & 50         & 0.8148439  & 0.5973066  & 0.04128091 & 0.09160423\\\\\n",
       "\t73 & 0.4        & 2          & 0          & 0.6        & 1          & 0.50       & 50         & 0.8204494  & 0.6145167  & 0.03416995 & 0.07310278\\\\\n",
       "\t76 & 0.4        & 2          & 0          & 0.6        & 1          & 0.75       & 50         & 0.8260549  & 0.6258709  & 0.04170029 & 0.09089356\\\\\n",
       "\t79 & 0.4        & 2          & 0          & 0.6        & 1          & 1.00       & 50         & 0.8260674  & 0.6258910  & 0.03381921 & 0.07290953\\\\\n",
       "\t82 & 0.4        & 2          & 0          & 0.8        & 1          & 0.50       & 50         & 0.8237578  & 0.6188301  & 0.04014638 & 0.08945097\\\\\n",
       "\t85 & 0.4        & 2          & 0          & 0.8        & 1          & 0.75       & 50         & 0.8361298  & 0.6457631  & 0.04147142 & 0.09159467\\\\\n",
       "\t88 & 0.4        & 2          & 0          & 0.8        & 1          & 1.00       & 50         & 0.8148065  & 0.6001120  & 0.04505389 & 0.09946370\\\\\n",
       "\t37 & 0.3        & 3          & 0          & 0.6        & 1          & 0.50       & 50         & 0.8327715  & 0.6402254  & 0.03609750 & 0.08089257\\\\\n",
       "\t40 & 0.3        & 3          & 0          & 0.6        & 1          & 0.75       & 50         & 0.8338951  & 0.6411144  & 0.03920229 & 0.08557255\\\\\n",
       "\t43 & 0.3        & 3          & 0          & 0.6        & 1          & 1.00       & 50         & 0.8249064  & 0.6215746  & 0.04214523 & 0.09292299\\\\\n",
       "\t46 & 0.3        & 3          & 0          & 0.8        & 1          & 0.50       & 50         & 0.8293883  & 0.6327620  & 0.04367676 & 0.09647361\\\\\n",
       "\t49 & 0.3        & 3          & 0          & 0.8        & 1          & 0.75       & 50         & 0.8361298  & 0.6465165  & 0.03974424 & 0.08604556\\\\\n",
       "\t52 & 0.3        & 3          & 0          & 0.8        & 1          & 1.00       & 50         & 0.8349938  & 0.6438811  & 0.03445080 & 0.07454968\\\\\n",
       "\t... & ... & ... & ... & ... & ... & ... & ... & ... & ... & ... & ...\\\\\n",
       "\t57 & 0.4        & 1          & 0          & 0.6        & 1          & 0.50       & 150        & 0.8170537  & 0.6088633  & 0.03967830 & 0.08646431\\\\\n",
       "\t60 & 0.4        & 1          & 0          & 0.6        & 1          & 0.75       & 150        & 0.8170787  & 0.6075935  & 0.04517046 & 0.10054178\\\\\n",
       "\t63 & 0.4        & 1          & 0          & 0.6        & 1          & 1.00       & 150        & 0.8148190  & 0.6037236  & 0.04499735 & 0.09737310\\\\\n",
       "\t66 & 0.4        & 1          & 0          & 0.8        & 1          & 0.50       & 150        & 0.8182022  & 0.6108358  & 0.04118420 & 0.09127238\\\\\n",
       "\t69 & 0.4        & 1          & 0          & 0.8        & 1          & 0.75       & 150        & 0.8159301  & 0.6040307  & 0.03793153 & 0.08558172\\\\\n",
       "\t72 & 0.4        & 1          & 0          & 0.8        & 1          & 1.00       & 150        & 0.8148315  & 0.6037497  & 0.04067354 & 0.08794103\\\\\n",
       "\t21 & 0.3        & 2          & 0          & 0.6        & 1          & 0.50       & 150        & 0.8249313  & 0.6237818  & 0.04881907 & 0.10482018\\\\\n",
       "\t24 & 0.3        & 2          & 0          & 0.6        & 1          & 0.75       & 150        & 0.8271536  & 0.6284596  & 0.03009296 & 0.06780047\\\\\n",
       "\t27 & 0.3        & 2          & 0          & 0.6        & 1          & 1.00       & 150        & 0.8237953  & 0.6201812  & 0.03350371 & 0.07277306\\\\\n",
       "\t30 & 0.3        & 2          & 0          & 0.8        & 1          & 0.50       & 150        & 0.8260549  & 0.6257682  & 0.03221092 & 0.07227748\\\\\n",
       "\t33 & 0.3        & 2          & 0          & 0.8        & 1          & 0.75       & 150        & 0.8271411  & 0.6261702  & 0.03530493 & 0.07950582\\\\\n",
       "\t36 & 0.3        & 2          & 0          & 0.8        & 1          & 1.00       & 150        & 0.8305243  & 0.6354118  & 0.03837048 & 0.08341792\\\\\n",
       "\t75 & 0.4        & 2          & 0          & 0.6        & 1          & 0.50       & 150        & 0.8159176  & 0.6051595  & 0.04539284 & 0.10143975\\\\\n",
       "\t78 & 0.4        & 2          & 0          & 0.6        & 1          & 0.75       & 150        & 0.8293758  & 0.6332687  & 0.03597345 & 0.07971198\\\\\n",
       "\t81 & 0.4        & 2          & 0          & 0.6        & 1          & 1.00       & 150        & 0.8316479  & 0.6395457  & 0.03783050 & 0.08011641\\\\\n",
       "\t84 & 0.4        & 2          & 0          & 0.8        & 1          & 0.50       & 150        & 0.8271286  & 0.6283819  & 0.03158352 & 0.06846343\\\\\n",
       "\t87 & 0.4        & 2          & 0          & 0.8        & 1          & 0.75       & 150        & 0.8293758  & 0.6323545  & 0.03750078 & 0.08326921\\\\\n",
       "\t90 & 0.4        & 2          & 0          & 0.8        & 1          & 1.00       & 150        & 0.8327341  & 0.6409549  & 0.04232199 & 0.09138420\\\\\n",
       "\t39 & 0.3        & 3          & 0          & 0.6        & 1          & 0.50       & 150        & 0.8226966  & 0.6186960  & 0.02208023 & 0.04955715\\\\\n",
       "\t42 & 0.3        & 3          & 0          & 0.6        & 1          & 0.75       & 150        & 0.8395006  & 0.6564600  & 0.03517712 & 0.07478497\\\\\n",
       "\t45 & 0.3        & 3          & 0          & 0.6        & 1          & 1.00       & 150        & 0.8282647  & 0.6313181  & 0.03276377 & 0.07133382\\\\\n",
       "\t48 & 0.3        & 3          & 0          & 0.8        & 1          & 0.50       & 150        & 0.8260300  & 0.6234660  & 0.03566748 & 0.07819844\\\\\n",
       "\t51 & 0.3        & 3          & 0          & 0.8        & 1          & 0.75       & 150        & 0.8294007  & 0.6314180  & 0.04198962 & 0.09076021\\\\\n",
       "\t54 & 0.3        & 3          & 0          & 0.8        & 1          & 1.00       & 150        & 0.8360924  & 0.6476669  & 0.03769462 & 0.08120549\\\\\n",
       "\t93 & 0.4        & 3          & 0          & 0.6        & 1          & 0.50       & 150        & 0.8147940  & 0.6004952  & 0.03066247 & 0.06833994\\\\\n",
       "\t96 & 0.4        & 3          & 0          & 0.6        & 1          & 0.75       & 150        & 0.8181898  & 0.6098985  & 0.03500017 & 0.07515441\\\\\n",
       "\t99 & 0.4        & 3          & 0          & 0.6        & 1          & 1.00       & 150        & 0.8282272  & 0.6312741  & 0.04512519 & 0.09727712\\\\\n",
       "\t102 & 0.4        & 3          & 0          & 0.8        & 1          & 0.50       & 150        & 0.8203870  & 0.6175539  & 0.02774708 & 0.06107577\\\\\n",
       "\t105 & 0.4        & 3          & 0          & 0.8        & 1          & 0.75       & 150        & 0.8294132  & 0.6330256  & 0.04845000 & 0.10439148\\\\\n",
       "\t108 & 0.4        & 3          & 0          & 0.8        & 1          & 1.00       & 150        & 0.8304869  & 0.6363228  & 0.03740496 & 0.07990741\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | eta | max_depth | gamma | colsample_bytree | min_child_weight | subsample | nrounds | Accuracy | Kappa | AccuracySD | KappaSD |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 0.3        | 1          | 0          | 0.6        | 1          | 0.50       | 50         | 0.8125968  | 0.5991972  | 0.04122726 | 0.08800752 |\n",
       "| 4 | 0.3        | 1          | 0          | 0.6        | 1          | 0.75       | 50         | 0.8137328  | 0.6033150  | 0.04631694 | 0.09784588 |\n",
       "| 7 | 0.3        | 1          | 0          | 0.6        | 1          | 1.00       | 50         | 0.8092260  | 0.5923297  | 0.04695794 | 0.09987783 |\n",
       "| 10 | 0.3        | 1          | 0          | 0.8        | 1          | 0.50       | 50         | 0.8137328  | 0.6024889  | 0.04570721 | 0.09643140 |\n",
       "| 13 | 0.3        | 1          | 0          | 0.8        | 1          | 0.75       | 50         | 0.8103496  | 0.5944208  | 0.03783577 | 0.08057837 |\n",
       "| 16 | 0.3        | 1          | 0          | 0.8        | 1          | 1.00       | 50         | 0.8137203  | 0.6024167  | 0.04358540 | 0.09209431 |\n",
       "| 55 | 0.4        | 1          | 0          | 0.6        | 1          | 0.50       | 50         | 0.8204619  | 0.6163252  | 0.03759774 | 0.08123917 |\n",
       "| 58 | 0.4        | 1          | 0          | 0.6        | 1          | 0.75       | 50         | 0.8170911  | 0.6087990  | 0.04119852 | 0.08801159 |\n",
       "| 61 | 0.4        | 1          | 0          | 0.6        | 1          | 1.00       | 50         | 0.8092260  | 0.5923270  | 0.04019822 | 0.08522559 |\n",
       "| 64 | 0.4        | 1          | 0          | 0.8        | 1          | 0.50       | 50         | 0.8069788  | 0.5872609  | 0.04083601 | 0.08554035 |\n",
       "| 67 | 0.4        | 1          | 0          | 0.8        | 1          | 0.75       | 50         | 0.8103620  | 0.5953182  | 0.04095376 | 0.08705461 |\n",
       "| 70 | 0.4        | 1          | 0          | 0.8        | 1          | 1.00       | 50         | 0.8114732  | 0.5975242  | 0.04182554 | 0.08883558 |\n",
       "| 19 | 0.3        | 2          | 0          | 0.6        | 1          | 0.50       | 50         | 0.8148315  | 0.5994115  | 0.04706839 | 0.10438694 |\n",
       "| 22 | 0.3        | 2          | 0          | 0.6        | 1          | 0.75       | 50         | 0.8215356  | 0.6135598  | 0.03768189 | 0.08381644 |\n",
       "| 25 | 0.3        | 2          | 0          | 0.6        | 1          | 1.00       | 50         | 0.8260674  | 0.6239229  | 0.04060450 | 0.09089583 |\n",
       "| 28 | 0.3        | 2          | 0          | 0.8        | 1          | 0.50       | 50         | 0.8215356  | 0.6146185  | 0.03204929 | 0.07075925 |\n",
       "| 31 | 0.3        | 2          | 0          | 0.8        | 1          | 0.75       | 50         | 0.8181898  | 0.6105928  | 0.03459707 | 0.07641250 |\n",
       "| 34 | 0.3        | 2          | 0          | 0.8        | 1          | 1.00       | 50         | 0.8148439  | 0.5973066  | 0.04128091 | 0.09160423 |\n",
       "| 73 | 0.4        | 2          | 0          | 0.6        | 1          | 0.50       | 50         | 0.8204494  | 0.6145167  | 0.03416995 | 0.07310278 |\n",
       "| 76 | 0.4        | 2          | 0          | 0.6        | 1          | 0.75       | 50         | 0.8260549  | 0.6258709  | 0.04170029 | 0.09089356 |\n",
       "| 79 | 0.4        | 2          | 0          | 0.6        | 1          | 1.00       | 50         | 0.8260674  | 0.6258910  | 0.03381921 | 0.07290953 |\n",
       "| 82 | 0.4        | 2          | 0          | 0.8        | 1          | 0.50       | 50         | 0.8237578  | 0.6188301  | 0.04014638 | 0.08945097 |\n",
       "| 85 | 0.4        | 2          | 0          | 0.8        | 1          | 0.75       | 50         | 0.8361298  | 0.6457631  | 0.04147142 | 0.09159467 |\n",
       "| 88 | 0.4        | 2          | 0          | 0.8        | 1          | 1.00       | 50         | 0.8148065  | 0.6001120  | 0.04505389 | 0.09946370 |\n",
       "| 37 | 0.3        | 3          | 0          | 0.6        | 1          | 0.50       | 50         | 0.8327715  | 0.6402254  | 0.03609750 | 0.08089257 |\n",
       "| 40 | 0.3        | 3          | 0          | 0.6        | 1          | 0.75       | 50         | 0.8338951  | 0.6411144  | 0.03920229 | 0.08557255 |\n",
       "| 43 | 0.3        | 3          | 0          | 0.6        | 1          | 1.00       | 50         | 0.8249064  | 0.6215746  | 0.04214523 | 0.09292299 |\n",
       "| 46 | 0.3        | 3          | 0          | 0.8        | 1          | 0.50       | 50         | 0.8293883  | 0.6327620  | 0.04367676 | 0.09647361 |\n",
       "| 49 | 0.3        | 3          | 0          | 0.8        | 1          | 0.75       | 50         | 0.8361298  | 0.6465165  | 0.03974424 | 0.08604556 |\n",
       "| 52 | 0.3        | 3          | 0          | 0.8        | 1          | 1.00       | 50         | 0.8349938  | 0.6438811  | 0.03445080 | 0.07454968 |\n",
       "| ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... |\n",
       "| 57 | 0.4        | 1          | 0          | 0.6        | 1          | 0.50       | 150        | 0.8170537  | 0.6088633  | 0.03967830 | 0.08646431 |\n",
       "| 60 | 0.4        | 1          | 0          | 0.6        | 1          | 0.75       | 150        | 0.8170787  | 0.6075935  | 0.04517046 | 0.10054178 |\n",
       "| 63 | 0.4        | 1          | 0          | 0.6        | 1          | 1.00       | 150        | 0.8148190  | 0.6037236  | 0.04499735 | 0.09737310 |\n",
       "| 66 | 0.4        | 1          | 0          | 0.8        | 1          | 0.50       | 150        | 0.8182022  | 0.6108358  | 0.04118420 | 0.09127238 |\n",
       "| 69 | 0.4        | 1          | 0          | 0.8        | 1          | 0.75       | 150        | 0.8159301  | 0.6040307  | 0.03793153 | 0.08558172 |\n",
       "| 72 | 0.4        | 1          | 0          | 0.8        | 1          | 1.00       | 150        | 0.8148315  | 0.6037497  | 0.04067354 | 0.08794103 |\n",
       "| 21 | 0.3        | 2          | 0          | 0.6        | 1          | 0.50       | 150        | 0.8249313  | 0.6237818  | 0.04881907 | 0.10482018 |\n",
       "| 24 | 0.3        | 2          | 0          | 0.6        | 1          | 0.75       | 150        | 0.8271536  | 0.6284596  | 0.03009296 | 0.06780047 |\n",
       "| 27 | 0.3        | 2          | 0          | 0.6        | 1          | 1.00       | 150        | 0.8237953  | 0.6201812  | 0.03350371 | 0.07277306 |\n",
       "| 30 | 0.3        | 2          | 0          | 0.8        | 1          | 0.50       | 150        | 0.8260549  | 0.6257682  | 0.03221092 | 0.07227748 |\n",
       "| 33 | 0.3        | 2          | 0          | 0.8        | 1          | 0.75       | 150        | 0.8271411  | 0.6261702  | 0.03530493 | 0.07950582 |\n",
       "| 36 | 0.3        | 2          | 0          | 0.8        | 1          | 1.00       | 150        | 0.8305243  | 0.6354118  | 0.03837048 | 0.08341792 |\n",
       "| 75 | 0.4        | 2          | 0          | 0.6        | 1          | 0.50       | 150        | 0.8159176  | 0.6051595  | 0.04539284 | 0.10143975 |\n",
       "| 78 | 0.4        | 2          | 0          | 0.6        | 1          | 0.75       | 150        | 0.8293758  | 0.6332687  | 0.03597345 | 0.07971198 |\n",
       "| 81 | 0.4        | 2          | 0          | 0.6        | 1          | 1.00       | 150        | 0.8316479  | 0.6395457  | 0.03783050 | 0.08011641 |\n",
       "| 84 | 0.4        | 2          | 0          | 0.8        | 1          | 0.50       | 150        | 0.8271286  | 0.6283819  | 0.03158352 | 0.06846343 |\n",
       "| 87 | 0.4        | 2          | 0          | 0.8        | 1          | 0.75       | 150        | 0.8293758  | 0.6323545  | 0.03750078 | 0.08326921 |\n",
       "| 90 | 0.4        | 2          | 0          | 0.8        | 1          | 1.00       | 150        | 0.8327341  | 0.6409549  | 0.04232199 | 0.09138420 |\n",
       "| 39 | 0.3        | 3          | 0          | 0.6        | 1          | 0.50       | 150        | 0.8226966  | 0.6186960  | 0.02208023 | 0.04955715 |\n",
       "| 42 | 0.3        | 3          | 0          | 0.6        | 1          | 0.75       | 150        | 0.8395006  | 0.6564600  | 0.03517712 | 0.07478497 |\n",
       "| 45 | 0.3        | 3          | 0          | 0.6        | 1          | 1.00       | 150        | 0.8282647  | 0.6313181  | 0.03276377 | 0.07133382 |\n",
       "| 48 | 0.3        | 3          | 0          | 0.8        | 1          | 0.50       | 150        | 0.8260300  | 0.6234660  | 0.03566748 | 0.07819844 |\n",
       "| 51 | 0.3        | 3          | 0          | 0.8        | 1          | 0.75       | 150        | 0.8294007  | 0.6314180  | 0.04198962 | 0.09076021 |\n",
       "| 54 | 0.3        | 3          | 0          | 0.8        | 1          | 1.00       | 150        | 0.8360924  | 0.6476669  | 0.03769462 | 0.08120549 |\n",
       "| 93 | 0.4        | 3          | 0          | 0.6        | 1          | 0.50       | 150        | 0.8147940  | 0.6004952  | 0.03066247 | 0.06833994 |\n",
       "| 96 | 0.4        | 3          | 0          | 0.6        | 1          | 0.75       | 150        | 0.8181898  | 0.6098985  | 0.03500017 | 0.07515441 |\n",
       "| 99 | 0.4        | 3          | 0          | 0.6        | 1          | 1.00       | 150        | 0.8282272  | 0.6312741  | 0.04512519 | 0.09727712 |\n",
       "| 102 | 0.4        | 3          | 0          | 0.8        | 1          | 0.50       | 150        | 0.8203870  | 0.6175539  | 0.02774708 | 0.06107577 |\n",
       "| 105 | 0.4        | 3          | 0          | 0.8        | 1          | 0.75       | 150        | 0.8294132  | 0.6330256  | 0.04845000 | 0.10439148 |\n",
       "| 108 | 0.4        | 3          | 0          | 0.8        | 1          | 1.00       | 150        | 0.8304869  | 0.6363228  | 0.03740496 | 0.07990741 |\n",
       "\n"
      ],
      "text/plain": [
       "    eta max_depth gamma colsample_bytree min_child_weight subsample nrounds\n",
       "1   0.3 1         0     0.6              1                0.50      50     \n",
       "4   0.3 1         0     0.6              1                0.75      50     \n",
       "7   0.3 1         0     0.6              1                1.00      50     \n",
       "10  0.3 1         0     0.8              1                0.50      50     \n",
       "13  0.3 1         0     0.8              1                0.75      50     \n",
       "16  0.3 1         0     0.8              1                1.00      50     \n",
       "55  0.4 1         0     0.6              1                0.50      50     \n",
       "58  0.4 1         0     0.6              1                0.75      50     \n",
       "61  0.4 1         0     0.6              1                1.00      50     \n",
       "64  0.4 1         0     0.8              1                0.50      50     \n",
       "67  0.4 1         0     0.8              1                0.75      50     \n",
       "70  0.4 1         0     0.8              1                1.00      50     \n",
       "19  0.3 2         0     0.6              1                0.50      50     \n",
       "22  0.3 2         0     0.6              1                0.75      50     \n",
       "25  0.3 2         0     0.6              1                1.00      50     \n",
       "28  0.3 2         0     0.8              1                0.50      50     \n",
       "31  0.3 2         0     0.8              1                0.75      50     \n",
       "34  0.3 2         0     0.8              1                1.00      50     \n",
       "73  0.4 2         0     0.6              1                0.50      50     \n",
       "76  0.4 2         0     0.6              1                0.75      50     \n",
       "79  0.4 2         0     0.6              1                1.00      50     \n",
       "82  0.4 2         0     0.8              1                0.50      50     \n",
       "85  0.4 2         0     0.8              1                0.75      50     \n",
       "88  0.4 2         0     0.8              1                1.00      50     \n",
       "37  0.3 3         0     0.6              1                0.50      50     \n",
       "40  0.3 3         0     0.6              1                0.75      50     \n",
       "43  0.3 3         0     0.6              1                1.00      50     \n",
       "46  0.3 3         0     0.8              1                0.50      50     \n",
       "49  0.3 3         0     0.8              1                0.75      50     \n",
       "52  0.3 3         0     0.8              1                1.00      50     \n",
       "... ... ...       ...   ...              ...              ...       ...    \n",
       "57  0.4 1         0     0.6              1                0.50      150    \n",
       "60  0.4 1         0     0.6              1                0.75      150    \n",
       "63  0.4 1         0     0.6              1                1.00      150    \n",
       "66  0.4 1         0     0.8              1                0.50      150    \n",
       "69  0.4 1         0     0.8              1                0.75      150    \n",
       "72  0.4 1         0     0.8              1                1.00      150    \n",
       "21  0.3 2         0     0.6              1                0.50      150    \n",
       "24  0.3 2         0     0.6              1                0.75      150    \n",
       "27  0.3 2         0     0.6              1                1.00      150    \n",
       "30  0.3 2         0     0.8              1                0.50      150    \n",
       "33  0.3 2         0     0.8              1                0.75      150    \n",
       "36  0.3 2         0     0.8              1                1.00      150    \n",
       "75  0.4 2         0     0.6              1                0.50      150    \n",
       "78  0.4 2         0     0.6              1                0.75      150    \n",
       "81  0.4 2         0     0.6              1                1.00      150    \n",
       "84  0.4 2         0     0.8              1                0.50      150    \n",
       "87  0.4 2         0     0.8              1                0.75      150    \n",
       "90  0.4 2         0     0.8              1                1.00      150    \n",
       "39  0.3 3         0     0.6              1                0.50      150    \n",
       "42  0.3 3         0     0.6              1                0.75      150    \n",
       "45  0.3 3         0     0.6              1                1.00      150    \n",
       "48  0.3 3         0     0.8              1                0.50      150    \n",
       "51  0.3 3         0     0.8              1                0.75      150    \n",
       "54  0.3 3         0     0.8              1                1.00      150    \n",
       "93  0.4 3         0     0.6              1                0.50      150    \n",
       "96  0.4 3         0     0.6              1                0.75      150    \n",
       "99  0.4 3         0     0.6              1                1.00      150    \n",
       "102 0.4 3         0     0.8              1                0.50      150    \n",
       "105 0.4 3         0     0.8              1                0.75      150    \n",
       "108 0.4 3         0     0.8              1                1.00      150    \n",
       "    Accuracy  Kappa     AccuracySD KappaSD   \n",
       "1   0.8125968 0.5991972 0.04122726 0.08800752\n",
       "4   0.8137328 0.6033150 0.04631694 0.09784588\n",
       "7   0.8092260 0.5923297 0.04695794 0.09987783\n",
       "10  0.8137328 0.6024889 0.04570721 0.09643140\n",
       "13  0.8103496 0.5944208 0.03783577 0.08057837\n",
       "16  0.8137203 0.6024167 0.04358540 0.09209431\n",
       "55  0.8204619 0.6163252 0.03759774 0.08123917\n",
       "58  0.8170911 0.6087990 0.04119852 0.08801159\n",
       "61  0.8092260 0.5923270 0.04019822 0.08522559\n",
       "64  0.8069788 0.5872609 0.04083601 0.08554035\n",
       "67  0.8103620 0.5953182 0.04095376 0.08705461\n",
       "70  0.8114732 0.5975242 0.04182554 0.08883558\n",
       "19  0.8148315 0.5994115 0.04706839 0.10438694\n",
       "22  0.8215356 0.6135598 0.03768189 0.08381644\n",
       "25  0.8260674 0.6239229 0.04060450 0.09089583\n",
       "28  0.8215356 0.6146185 0.03204929 0.07075925\n",
       "31  0.8181898 0.6105928 0.03459707 0.07641250\n",
       "34  0.8148439 0.5973066 0.04128091 0.09160423\n",
       "73  0.8204494 0.6145167 0.03416995 0.07310278\n",
       "76  0.8260549 0.6258709 0.04170029 0.09089356\n",
       "79  0.8260674 0.6258910 0.03381921 0.07290953\n",
       "82  0.8237578 0.6188301 0.04014638 0.08945097\n",
       "85  0.8361298 0.6457631 0.04147142 0.09159467\n",
       "88  0.8148065 0.6001120 0.04505389 0.09946370\n",
       "37  0.8327715 0.6402254 0.03609750 0.08089257\n",
       "40  0.8338951 0.6411144 0.03920229 0.08557255\n",
       "43  0.8249064 0.6215746 0.04214523 0.09292299\n",
       "46  0.8293883 0.6327620 0.04367676 0.09647361\n",
       "49  0.8361298 0.6465165 0.03974424 0.08604556\n",
       "52  0.8349938 0.6438811 0.03445080 0.07454968\n",
       "... ...       ...       ...        ...       \n",
       "57  0.8170537 0.6088633 0.03967830 0.08646431\n",
       "60  0.8170787 0.6075935 0.04517046 0.10054178\n",
       "63  0.8148190 0.6037236 0.04499735 0.09737310\n",
       "66  0.8182022 0.6108358 0.04118420 0.09127238\n",
       "69  0.8159301 0.6040307 0.03793153 0.08558172\n",
       "72  0.8148315 0.6037497 0.04067354 0.08794103\n",
       "21  0.8249313 0.6237818 0.04881907 0.10482018\n",
       "24  0.8271536 0.6284596 0.03009296 0.06780047\n",
       "27  0.8237953 0.6201812 0.03350371 0.07277306\n",
       "30  0.8260549 0.6257682 0.03221092 0.07227748\n",
       "33  0.8271411 0.6261702 0.03530493 0.07950582\n",
       "36  0.8305243 0.6354118 0.03837048 0.08341792\n",
       "75  0.8159176 0.6051595 0.04539284 0.10143975\n",
       "78  0.8293758 0.6332687 0.03597345 0.07971198\n",
       "81  0.8316479 0.6395457 0.03783050 0.08011641\n",
       "84  0.8271286 0.6283819 0.03158352 0.06846343\n",
       "87  0.8293758 0.6323545 0.03750078 0.08326921\n",
       "90  0.8327341 0.6409549 0.04232199 0.09138420\n",
       "39  0.8226966 0.6186960 0.02208023 0.04955715\n",
       "42  0.8395006 0.6564600 0.03517712 0.07478497\n",
       "45  0.8282647 0.6313181 0.03276377 0.07133382\n",
       "48  0.8260300 0.6234660 0.03566748 0.07819844\n",
       "51  0.8294007 0.6314180 0.04198962 0.09076021\n",
       "54  0.8360924 0.6476669 0.03769462 0.08120549\n",
       "93  0.8147940 0.6004952 0.03066247 0.06833994\n",
       "96  0.8181898 0.6098985 0.03500017 0.07515441\n",
       "99  0.8282272 0.6312741 0.04512519 0.09727712\n",
       "102 0.8203870 0.6175539 0.02774708 0.06107577\n",
       "105 0.8294132 0.6330256 0.04845000 0.10439148\n",
       "108 0.8304869 0.6363228 0.03740496 0.07990741"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "controle_treinamento = trainControl(method = 'cv', number = 10)\n",
    "df$Survived = factor(df$Survived)\n",
    "modelo = train(Survived ~ ., data = df, trControl = controle_treinamento, method = 'xgbTree', verbose = FALSE )\n",
    "modelo$results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b9350f-ebcf-4122-a8e0-6df6f8bc58ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
